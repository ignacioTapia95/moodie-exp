{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22a1ec56-d166-4bb5-b040-cf6a44626c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cbdde9d-ab0f-4885-a69a-1315301ff7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "url = \"https://lienzocreativo.com/blog/wp-content/uploads/2020/03/plano-entero.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c23f53b4-7a93-4c60-8b0c-20c9acda6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Extreme Close-Up: Frames a very small part of the subject, such as the eyes, lips, or a specific object detail, filling the entire frame\",\n",
    "    \"Close-Up: Frames the subject’s face from just below the chin to the top of the head, occupying most of the frame\",\n",
    "    \"Medium Close-Up: Frames the subject from the shoulders or chest up\",\n",
    "    \"Medium Shot: Frames the subject from the waist up\",\n",
    "    \"Medium Long Shot: Frames the subject from mid-thigh or knees up\",\n",
    "    \"Long Shot: Frames the subject’s entire body from head to toe, with space above and below the subject\",\n",
    "    \"Extreme Long Shot: Frames the subject or scene from a great distance, showing the subject very small or the environment in full\",\n",
    "    \"Two-Shot: Frames two subjects within the same shot, either from the waist up or showing their full bodies.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb5e2fdb-e556-4d96-bf4b-b6d0c21a19da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Medium Long Shot: Frames the subject from mid-thigh or knees up',\n",
       " tensor(0.5439, grad_fn=<AmaxBackward0>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(text=categories, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "categories[probs.argmax()], probs.amax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b94e72-de7c-48be-9f77-7986148e4b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
